# .aicf Directory - AI Memory System

**Phase 6-8 Architecture** - Automatic conversation capture and intelligent memory dropoff

This directory contains **AI-optimized memory files** that are automatically generated from your LLM conversations.

---

## 📁 Directory Structure

```
.aicf/
├── recent/          # Recent conversations (0-2 days) - FULL detail
├── sessions/        # Daily session files (2-7 days) - FULL detail
├── medium/          # Medium-term memory (7-14 days) - SUMMARY
├── old/             # Old memory (14-30 days) - KEY_POINTS
├── archive/         # Archive (30+ days) - SINGLE_LINE
├── config.json      # Configuration file
├── README.md        # This file
├── .permissions.aicf       # Permission tracking (automatic mode)
└── .watcher-config.json    # Watcher configuration (automatic mode)
```

---

## 🔄 How It Works

### **Phase 6: Cache-First Architecture**

Every 5 minutes, the watcher:

1. Reads conversations from your LLM library (Augment, Claude, etc.)
2. Writes to `.cache/llm/{platform}/chunk-*.json`
3. Consolidates chunks into `.aicf/recent/{date}_{id}.aicf`

### **Phase 6.5: Session Consolidation**

Every 5 minutes, the consolidator:

1. Reads all files in `.aicf/recent/`
2. Groups by date
3. Writes to `.aicf/sessions/{date}-session.aicf`

### **Phase 7: Memory Dropoff Strategy**

Every 5 minutes, the dropoff agent:

1. Checks age of session files
2. Compresses by age:
   - **0-2 days** → `.aicf/sessions/` (FULL detail)
   - **2-7 days** → `.aicf/sessions/` (FULL detail)
   - **7-14 days** → `.aicf/medium/` (SUMMARY)
   - **14-30 days** → `.aicf/old/` (KEY_POINTS)
   - **30+ days** → `.aicf/archive/` (SINGLE_LINE)

---

## 📖 AICF Format

AICF (AI Context Format) uses pipe-delimited structured data:

```
@CONVERSATION|id=C1|date=2025-10-25|messages=50|tokens=12345
@USER|timestamp=2025-10-25T10:00:00Z|content=How do I implement feature X?
@ASSISTANT|timestamp=2025-10-25T10:01:00Z|content=Here's how to implement feature X...
@DECISION|name=Use TypeScript|reasoning=Better type safety|impact=HIGH
```

**Benefits:**

- ⚡ **5x more efficient** than markdown (100 tokens vs 500 tokens)
- 🔍 **Structured** - enables precise queries and analysis
- 🤖 **AI-optimized** - easier for AI to parse and process
- 📊 **Compact** - pipe-separated values save space

---

## 🎯 Why Both .ai/ and .aicf/?

**`.ai/` files** (Human-readable, manual):

- ✅ Static documentation (code-style, design-system, etc.)
- ✅ Protected from automatic systems
- ✅ Manual updates only

**`.aicf/` files** (AI-optimized, automatic):

- ⚡ Automatic conversation capture
- 🔄 Intelligent memory dropoff
- 📊 Structured data for analysis
- 🤖 AI-to-AI communication

---

## 🚀 Getting Started

### **Automatic Mode** (Recommended)

1. Initialize with automatic mode:

   ```bash
   aice init --automatic
   ```

2. Start the watcher:

   ```bash
   aice watch
   ```

3. The system automatically:
   - Captures conversations from your LLM
   - Consolidates into session files
   - Applies intelligent memory dropoff

### **Manual Mode**

1. Initialize with manual mode:

   ```bash
   aice init --manual
   ```

2. Ask your LLM to update memory files after each session

---

## 💡 Tips

- **Automatic mode** - Set it and forget it! The watcher handles everything.
- **Check sessions/** - Review daily session files to see what was captured
- **Legacy data** - If you migrated from v2.0.1, check `legacy_memory/` folder
- **Commit to Git** - Session files are gitignored, but you can commit important ones

---

## 🤖 For AI Assistants

When reading this project's context:

1. **Read `.ai/` files first** for static documentation
2. **Read `.aicf/sessions/` for recent conversations** (last 7 days)
3. **Read `.aicf/medium/` for older context** (7-14 days)
4. **Read `.aicf/old/` for historical context** (14-30 days)
5. **Skip `.aicf/archive/`** unless specifically needed

**Priority order:** `.ai/` → `sessions/` → `medium/` → `old/` → `archive/`

---

**Generated by create-ai-chat-context-experimental v3.x** - Automatic AI memory system!
